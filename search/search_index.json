{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"mBank Hacker Documentation","text":""},{"location":"#description","title":"Description","text":"<p>mBank Hacker is a tool designed to interact with mBank's chat system, process financial data, and simulate various banking operations for testing and development purposes. The system provides tools for analyzing transactions, generating fake transfers, and testing edge cases in financial operations.</p>"},{"location":"#configuration","title":"Configuration","text":"<p>The system's behavior can be configured in the <code>src/config.py</code> file. Key configuration options include:</p> <ul> <li>Transaction File Path: Path to the CSV file containing transaction data.</li> <li>Together API Model: Specifies the model used for prompt generation (e.g., <code>\"gpt-4\"</code>).</li> </ul>"},{"location":"commands/","title":"Commands","text":""},{"location":"commands/#crate-enviroment","title":"Crate Enviroment","text":"<pre><code>make create_environment\n</code></pre>"},{"location":"commands/#install-python-dependencies","title":"Install Python Dependencies","text":"<pre><code>make requirements\n</code></pre>"},{"location":"commands/#using-azure-openai-api","title":"\u25b6\ufe0f Using Azure OpenAI API","text":"<p>To enable Azure OpenAI-based summaries:</p> <ol> <li>Create a <code>.env</code> file in the project root directory.</li> <li>Add your Azure OpenAI credentials:    ```env    AZURE_OPENAI_KEY=your-api-key-here    AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/    AZURE_OPENAI_DEPLOYMENT_NAME=your-deployment-name</li> <li>Make sure you have billing enabled</li> </ol>"},{"location":"commands/#using-a-local-model","title":"\u25b6\ufe0f Using a Local Model","text":"<p>If you prefer to use a local LLM instead of the OpenAI API: 1. open <code>config.py</code> 2. set <code>USE_OPENAI = False</code> 3. Optionally configure <code>SUMMARY_MODEL</code> and <code>DEVICE</code> Note: On first use, the model will be downloaded from Hugging Face. This may take a few minutes depending on your internet speed</p>"},{"location":"commands/#delete-all-compiled-python-files","title":"Delete all compiled Python files","text":"<p>Deletes all compiled Python files (.pyc, .pyo) and pycache directories.</p> <pre><code>make clean\n</code></pre>"},{"location":"commands/#lint-using-flake8-and-black","title":"Lint using flake8 and black","text":"<p>Lints the source code using flake8 and black. Use make format to format the code.</p> <pre><code>make lint\n</code></pre>"},{"location":"commands/#format-source-code-with-black","title":"Format source code with black","text":"<p>Formats the source code using black.</p> <pre><code>make format\n</code></pre>"},{"location":"commands/#prepare-knowladge-base","title":"Prepare Knowladge Base","text":"<pre><code>make prepare_kb\n</code></pre>"},{"location":"commands/#have-fun-with-code-rag","title":"Have fun with CODE RAG","text":"<pre><code>streamlit run src/main.py --server.fileWatcherType=none\n</code></pre>"},{"location":"commands/#replicate-experiment","title":"Replicate Experiment","text":"<p>Evaluate on validation data 1. Download file from here 2. Run <code>make evaluate</code>.</p>"},{"location":"commands/#replicate-experiment_1","title":"Replicate Experiment","text":"<p>Replicates my experiments  For this you need an acount on Weights &amp; Biases</p> <pre><code>make hyperparameter_experiment\n</code></pre> <pre><code>make query_expansion_experiment\n</code></pre>"},{"location":"commands/#serve-documentation","title":"Serve documentation","text":"<p>Serves the documentation locally using mkdocs.</p> <pre><code>make docs_serve\n</code></pre>"},{"location":"commands/#build-documentation","title":"Build documentation","text":"<p>Builds the documentation using mkdocs.</p> <pre><code>make docs_build\n</code></pre>"},{"location":"commands/#create-llm-summaries-dataset","title":"Create LLM summaries dataset","text":"<p>Generates synthetic dataset for summary model training.</p> <pre><code>make generate_summary_dataset\n</code></pre>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before starting with the project, make sure you have installed all the required dependencies. You can do this by running the following command:</p> <pre><code>make create_environment\n</code></pre> <pre><code>make requirements\n</code></pre> <p>By default, the system uses the OpenAI API to generate natural language summaries of retrieved code files.</p>"},{"location":"getting-started/#using-azure-openai-api","title":"\u25b6\ufe0f Using Azure OpenAI API","text":"<p>To enable Azure OpenAI-based summaries:</p> <ol> <li>Create a <code>.env</code> file in the project root directory.</li> <li>Add your Azure OpenAI credentials:    ```env    AZURE_OPENAI_KEY=your-api-key-here    AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/    AZURE_OPENAI_DEPLOYMENT_NAME=your-deployment-name</li> <li>Make sure you have billing enabled</li> </ol>"},{"location":"getting-started/#using-a-local-model","title":"\u25b6\ufe0f Using a Local Model","text":"<p>If you prefer to use a local LLM instead of the OpenAI API: 1. open <code>config.py</code> 2. set <code>USE_OPENAI = False</code> 3. Optionally configure <code>SUMMARY_MODEL</code> and <code>DEVICE</code> Note: On first use, the model will be downloaded from Hugging Face. This may take a few minutes depending on your internet speed</p>"},{"location":"getting-started/#step-1-prepare-knowladge-base","title":"Step 1: Prepare Knowladge Base","text":"<pre><code>make prepare_kb\n</code></pre>"},{"location":"getting-started/#step-2-inference-with-system","title":"Step 2: Inference with System","text":"<p>run</p> <pre><code>uv run src/main.py\n</code></pre> <p>Now you can input your question, and the system will return an answer with paths to the relevant files.</p>"},{"location":"getting-started/#step-3optional-replicate-experiment","title":"Step 3:(Optional) Replicate Experiment","text":"<p>You can reproduce experiments by preparing validation dataset by downloading file from here and saving it as <code>/data/escrcpy_val.json</code>. Then you can run <code>make hyperparameter_experiment</code> and <code>make query_expansion_experiment</code> or even <code>make reranker_experiment</code>. Important - before running experiment you need to do step 1 Prepare Knowladge Base</p>"},{"location":"src/mBank_chat_handler/","title":"mBank Chat Handler","text":""},{"location":"src/mBank_chat_handler/#src.utils.extract_conversation_id","title":"<code>extract_conversation_id(text)</code>","text":"<p>Extracts the Conversation ID from the given text.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text containing the Conversation ID.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>str | None: The extracted Conversation ID, or None if not found.</p> Source code in <code>src/utils.py</code> <pre><code>def extract_conversation_id(text: str) -&gt; str | None:\n    \"\"\"\n    Extracts the Conversation ID from the given text.\n\n    Args:\n        text (str): The text containing the Conversation ID.\n\n    Returns:\n        str | None: The extracted Conversation ID, or None if not found.\n    \"\"\"\n    match = re.search(r'Conversation:\\s*([a-f0-9\\-]+)', text)\n    if match:\n        return match.group(1)\n    return None\n</code></pre>"},{"location":"src/mBank_chat_handler/#src.utils.log_response","title":"<code>log_response(response, sender, log_path='prompt_logs.txt')</code>","text":"<p>Logs the model's response to a file in JSON format.</p> <p>Parameters:</p> Name Type Description Default <code>response</code> <code>str</code> <p>The full response from the model.</p> required <code>sender</code> <code>str</code> <p>The sender of the message.</p> required <code>log_path</code> <code>str</code> <p>Path to the log file.</p> <code>'prompt_logs.txt'</code> Source code in <code>src/utils.py</code> <pre><code>def log_response(\n        response: str,\n        sender: str,\n        log_path: str = \"prompt_logs.txt\"\n        ) -&gt; None:\n    \"\"\"\n    Logs the model's response to a file in JSON format.\n\n    Args:\n        response (str): The full response from the model.\n        sender (str): The sender of the message.\n        log_path (str): Path to the log file.\n    \"\"\"\n    with open(log_path, \"a\") as f:\n        json.dump({sender: response}, f, ensure_ascii=False)\n        f.write(\"\\n\")\n</code></pre>"},{"location":"src/prompt_generation/","title":"Prompt Generation","text":""},{"location":"src/prompt_generation/#src.prompt_genaration.prompt_generator.PromptGenerator","title":"<code>PromptGenerator</code>","text":"Source code in <code>src/prompt_genaration/prompt_generator.py</code> <pre><code>class PromptGenerator:\n    def __init__(self, model: str):\n        \"\"\"\n        Inicialize the PromptGenerator with the specified model.\n\n        Args:\n            model (str): Model name to be used with Together API.\n        \"\"\"\n        self.client = Together()\n        self.model = model\n        self.tools = tools\n\n    def generate_first_prompt(\n        self,\n        system_prompt: str,\n        mbank_start_text: str = START_PROMPT,\n        temperature: Optional[float] = None,\n    ) -&gt; str:\n        \"\"\"\n        Generate the first prompt using the system prompt.\n\n        Args:\n            system_prompt (str): The system prompt to be used.\n            mbank_start_text (str): The starting text for mBank.\n            temperature (float, optional): The temperature for the generation. Default is None.\n\n        Returns:\n            str: The generated prompt.\n        \"\"\"\n\n        messages = [\n            {\n                \"role\": \"system\",\n                \"content\": system_prompt,\n            },\n            {\n                \"role\": \"user\",\n                \"content\": mbank_start_text,\n            },\n        ]\n        try:\n            response = self.client.chat.completions.create(\n                model=self.model, messages=messages, temperature=temperature\n            )\n            return response.choices[0].message.content.strip()\n\n        except Exception as e:\n            print(f\"Error during API call: {e}\")\n            return \"Error: Unable to generate summary.\"\n\n    def _add_system_prompt(\n        self, messages: list[dict], extra_system_prompt: Optional[str]\n    ) -&gt; None:\n        \"\"\"\n        Adds an extra system prompt to the messages.\n\n        Args:\n            messages (list[dict]): A list of message dictionaries for the conversation.\n            extra_system_prompt (str): Additional system prompt to include.\n        \"\"\"\n        if extra_system_prompt:\n            messages.append({\"role\": \"system\", \"content\": extra_system_prompt})\n\n    def _call_together_api(self, messages: list[dict], temperature: Optional[float]):\n        \"\"\"\n        Calls the Together API with the provided messages.\n\n        Args:\n            messages (list[dict]): A list of message dictionaries for the conversation.\n            temperature (float, optional): The temperature for the generation. Defaults to None.\n\n        Returns:\n            Response: The response from the Together API.\n        \"\"\"\n        return self.client.chat.completions.create(\n            model=self.model,\n            messages=messages,\n            temperature=temperature,\n            tools=self.tools,\n            tool_choice=\"auto\",\n        )\n\n    def _handle_tool_calls(self, tool_calls: list, messages: list[dict]) -&gt; None:\n        \"\"\"\n        Handles tool calls and appends results to messages.\n\n        Args:\n            tool_calls (list): A list of tool call objects.\n            messages (list[dict]): A list of message dictionaries for the conversation.\n        \"\"\"\n        for call in tool_calls:\n            tool_name = call.function.name\n            args = json.loads(call.function.arguments)\n\n            result = self._execute_tool(tool_name, args)\n            messages.append({\"role\": \"tool\", \"content\": result})\n\n    def _execute_tool(self, tool_name: str, args: dict) -&gt; str:\n        \"\"\"\n        Executes the appropriate tool based on the tool name.\n\n        Args:\n            tool_name (str): The name of the tool to execute.\n            args (dict): The arguments for the tool.\n\n        Returns:\n            str: A JSON string containing the tool name and its result.\n        \"\"\"\n        try:\n            if tool_name == \"get_operations_for_account\":\n                result_df = get_operations_for_account(args[\"account_name\"])\n                result = result_df.to_dict(orient=\"records\")\n            elif tool_name == \"summarize_expenses_by_category\":\n                result_df = summarize_expenses_by_category(args.get(\"account_name\"))\n                result = result_df.to_dict(orient=\"records\")\n            elif tool_name == \"simulate_fake_transfer\":\n                result_df = simulate_fake_transfer(\n                    args.get(\"account_name\"),\n                    args.get(\"category\"),\n                    args.get(\"amount\"),\n                    args.get(\"description\"),\n                    args.get(\"operation_date\"),\n                    args.get(\"balance\"),\n                )\n                result = result_df.to_dict(orient=\"records\")\n            elif tool_name == \"misscalculate_balance\":\n                result_df = misscalculate_balance(\n                    args.get(\"account_name\"),\n                    args.get(\"category\"),\n                    args.get(\"amount\"),\n                    args.get(\"description\"),\n                    args.get(\"operation_date\"),\n                    args.get(\"balance\"),\n                )\n                result = result_df.to_dict(orient=\"records\")\n            elif tool_name == \"misscalculate_currency_conversion_from_PLN\":\n                result = str(\n                    misscalculate_currency_conversion_from_PLN(\n                        args[\"amount\"], args.get(\"fake_conversion_rate\")\n                    )\n                )\n            elif tool_name == \"misscalculate_currency_conversion_from_EUR\":\n                result = str(\n                    misscalculate_currency_conversion_from_EUR(\n                        args[\"amount\"], args.get(\"fake_conversion_rate\")\n                    )\n                )\n            else:\n                result = f\"Unknown tool: {tool_name}\"\n\n            return json.dumps(\n                {\"tool_name\": tool_name, \"result\": result}, indent=2, ensure_ascii=False\n            )\n\n        except Exception as e:\n            return json.dumps(\n                {\"tool_name\": tool_name, \"error\": str(e)}, indent=2, ensure_ascii=False\n            )\n\n    def _handle_context_too_long(self, messages: list[dict]) -&gt; None:\n        \"\"\"\n        Handles the case where the context is too long by removing the second oldest message.\n\n        Args:\n            messages (list[dict]): A list of message dictionaries for the conversation.\n        \"\"\"\n        print(\"Context too long. Removing the second oldest message and retrying...\")\n        messages.pop(1)\n\n    def generate_next_prompt(\n        self,\n        messages: list[dict],\n        extra_system_prompt: str = \"\",\n        temperature: Optional[float] = None,\n    ) -&gt; str:\n        \"\"\"\n        Generate the next prompt based on the provided messages and tools.\n\n        Args:\n            messages (list[dict]): A list of message dictionaries for the conversation.\n            extra_system_prompt (str, optional): Additional system prompt to include. Defaults to \"\".\n            temperature (float, optional): The temperature for the generation. Defaults to None.\n\n        Returns:\n            str: The generated response or tool result.\n        \"\"\"\n        self._add_system_prompt(messages, extra_system_prompt)\n\n        while len(messages) &gt; 1:\n            try:\n                response = self._call_together_api(messages, temperature)\n                message = response.choices[0].message\n\n                if hasattr(message, \"tool_calls\") and len(message.tool_calls) &gt; 0:\n                    self._handle_tool_calls(message.tool_calls, messages)\n                    return self.generate_next_prompt(\n                        messages=messages,\n                        extra_system_prompt=extra_system_prompt,\n                        temperature=temperature,\n                    )\n\n                return message.content.strip()\n\n            except InvalidRequestError as e:\n                self._handle_context_too_long(messages)\n            except Exception as e:\n                print(f\"Error during API call: {e}\")\n                return \"Error: Unable to generate the next prompt.\"\n\n        return (\n            \"Error: Unable to generate the next prompt due to excessive context length.\"\n        )\n</code></pre>"},{"location":"src/prompt_generation/#src.prompt_genaration.prompt_generator.PromptGenerator.__init__","title":"<code>__init__(model)</code>","text":"<p>Inicialize the PromptGenerator with the specified model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>Model name to be used with Together API.</p> required Source code in <code>src/prompt_genaration/prompt_generator.py</code> <pre><code>def __init__(self, model: str):\n    \"\"\"\n    Inicialize the PromptGenerator with the specified model.\n\n    Args:\n        model (str): Model name to be used with Together API.\n    \"\"\"\n    self.client = Together()\n    self.model = model\n    self.tools = tools\n</code></pre>"},{"location":"src/prompt_generation/#src.prompt_genaration.prompt_generator.PromptGenerator.generate_first_prompt","title":"<code>generate_first_prompt(system_prompt, mbank_start_text=START_PROMPT, temperature=None)</code>","text":"<p>Generate the first prompt using the system prompt.</p> <p>Parameters:</p> Name Type Description Default <code>system_prompt</code> <code>str</code> <p>The system prompt to be used.</p> required <code>mbank_start_text</code> <code>str</code> <p>The starting text for mBank.</p> <code>START_PROMPT</code> <code>temperature</code> <code>float</code> <p>The temperature for the generation. Default is None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The generated prompt.</p> Source code in <code>src/prompt_genaration/prompt_generator.py</code> <pre><code>def generate_first_prompt(\n    self,\n    system_prompt: str,\n    mbank_start_text: str = START_PROMPT,\n    temperature: Optional[float] = None,\n) -&gt; str:\n    \"\"\"\n    Generate the first prompt using the system prompt.\n\n    Args:\n        system_prompt (str): The system prompt to be used.\n        mbank_start_text (str): The starting text for mBank.\n        temperature (float, optional): The temperature for the generation. Default is None.\n\n    Returns:\n        str: The generated prompt.\n    \"\"\"\n\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": system_prompt,\n        },\n        {\n            \"role\": \"user\",\n            \"content\": mbank_start_text,\n        },\n    ]\n    try:\n        response = self.client.chat.completions.create(\n            model=self.model, messages=messages, temperature=temperature\n        )\n        return response.choices[0].message.content.strip()\n\n    except Exception as e:\n        print(f\"Error during API call: {e}\")\n        return \"Error: Unable to generate summary.\"\n</code></pre>"},{"location":"src/prompt_generation/#src.prompt_genaration.prompt_generator.PromptGenerator.generate_next_prompt","title":"<code>generate_next_prompt(messages, extra_system_prompt='', temperature=None)</code>","text":"<p>Generate the next prompt based on the provided messages and tools.</p> <p>Parameters:</p> Name Type Description Default <code>messages</code> <code>list[dict]</code> <p>A list of message dictionaries for the conversation.</p> required <code>extra_system_prompt</code> <code>str</code> <p>Additional system prompt to include. Defaults to \"\".</p> <code>''</code> <code>temperature</code> <code>float</code> <p>The temperature for the generation. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The generated response or tool result.</p> Source code in <code>src/prompt_genaration/prompt_generator.py</code> <pre><code>def generate_next_prompt(\n    self,\n    messages: list[dict],\n    extra_system_prompt: str = \"\",\n    temperature: Optional[float] = None,\n) -&gt; str:\n    \"\"\"\n    Generate the next prompt based on the provided messages and tools.\n\n    Args:\n        messages (list[dict]): A list of message dictionaries for the conversation.\n        extra_system_prompt (str, optional): Additional system prompt to include. Defaults to \"\".\n        temperature (float, optional): The temperature for the generation. Defaults to None.\n\n    Returns:\n        str: The generated response or tool result.\n    \"\"\"\n    self._add_system_prompt(messages, extra_system_prompt)\n\n    while len(messages) &gt; 1:\n        try:\n            response = self._call_together_api(messages, temperature)\n            message = response.choices[0].message\n\n            if hasattr(message, \"tool_calls\") and len(message.tool_calls) &gt; 0:\n                self._handle_tool_calls(message.tool_calls, messages)\n                return self.generate_next_prompt(\n                    messages=messages,\n                    extra_system_prompt=extra_system_prompt,\n                    temperature=temperature,\n                )\n\n            return message.content.strip()\n\n        except InvalidRequestError as e:\n            self._handle_context_too_long(messages)\n        except Exception as e:\n            print(f\"Error during API call: {e}\")\n            return \"Error: Unable to generate the next prompt.\"\n\n    return (\n        \"Error: Unable to generate the next prompt due to excessive context length.\"\n    )\n</code></pre>"},{"location":"src/prompt_generation/#src.prompt_genaration.system_prompt_generator.SystemPromptGenerator","title":"<code>SystemPromptGenerator</code>","text":"Source code in <code>src/prompt_genaration/system_prompt_generator.py</code> <pre><code>class SystemPromptGenerator:\n    def __init__(self):\n        self.system_prompt = self._load_json(SYSTEM_PROMPT_FILE_PATH)\n        self.examples = self._load_json(EXAMPLES_FILE_PATH)\n\n    def _load_json(self, file_path: Path) -&gt; dict:\n        \"\"\"\n        Load JSON data from a file.\n        \"\"\"\n        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n            data = json.load(file)\n        return data\n\n    def _get_category_dict(self, category: str = \"\") -&gt; tuple[dict, str]:\n        \"\"\"\n        Get the dictionary for a specific category from the system prompts.\n\n        Args:\n            category (str): The category to filter prompts. If empty, return a random prompt.\n\n        Returns:\n            tuple: A tuple containing the dictionary for the given category or a random one if no category is provided,\n                and the name of the selected category.\n        \"\"\"\n        if category:\n            filtered_prompts = [\n                p for p in self.system_prompt if p[\"category\"] == category\n            ]\n            if not filtered_prompts:\n                raise ValueError(f\"No prompts found for category: {category}\")\n            selected_prompt = filtered_prompts[0]\n        else:\n            selected_prompt = random.choice(self.system_prompt)\n\n        return selected_prompt, selected_prompt[\"category\"]\n\n    def _get_examples(self, category: str, max_examples) -&gt; str:\n        \"\"\"\n        Get the examples for the specified category.\n\n        Args:\n            category (str): The category to filter examples.\n            max_examples (int): The maximum number of examples to include.\n\n        Returns:\n            str: The examples for the given category, joined as a single string.\n        \"\"\"\n        filtered_examples = [e for e in self.examples if e[\"category\"] == category]\n\n        if not filtered_examples:\n            raise ValueError(f\"No examples found for category: {category}\")\n\n        examples_list = filtered_examples[0][\"examples\"]\n\n        selected_examples = random.sample(\n            examples_list, min(len(examples_list), max_examples)\n        )\n\n        return \"\".join(selected_examples)\n\n    def _get_specific_parts(\n        self, prompt_dict: dict, part_type: str, max_parts: int = 3\n    ) -&gt; str:\n        \"\"\"\n        Get the specyfic part for the prompt.\n\n        Args:\n            prompt_dict (dict): The dictionary containing the system_prompt_parts.\n            part_type (str): The type of part to retrieve (\"focus\", \"guidelines\")\n            max_parts (int): The maximum number of parts to include.\n\n        Returns:\n            str: The focus part of the prompt.\n        \"\"\"\n        parts = prompt_dict[part_type]\n        if len(parts) &gt; max_parts:\n            parts = random.sample(parts, max_parts)\n        return \"\\n\".join(parts)\n\n    def get_system_prompt(self, category: str = \"\", add_examples: bool = True) -&gt; str:\n        \"\"\"\n        Generate a system prompt based on the specified category.\n\n        This function retrieves a system prompt for a given category, optionally appending examples.\n        If no category is provided, a random prompt is selected. The function also determines whether\n        the prompt is in Polish or English based on the category name.\n\n        Args:\n            category (str): The category to filter prompts. If empty, a random prompt is selected.\n            add_examples (bool): Whether to append examples to the generated prompt. Defaults to True.\n\n        Returns:\n            str: The formatted system prompt, including focus, guidelines, and optionally examples.\n\n        Raises:\n            ValueError: If the specified category does not exist in the system prompts.\n        \"\"\"\n        pl = True if category.endswith(\"PL\") else False\n        prompt_dict, category = self._get_category_dict(category)\n        focus = self._get_specific_parts(prompt_dict, \"focus\", max_parts=2)\n        guidelines = self._get_specific_parts(prompt_dict, \"guidelines\", max_parts=1)\n\n        system_prompt = (\n            prompt_dict[\"system prompt\"] + \"\\n\\n\" + focus + \"\\n\\n\" + guidelines\n        )\n\n        if add_examples:\n            examples = self._get_examples(category, max_examples=3)\n            examples_intro = \"\\n\\nPrzyk\u0142ady:\\n\" if pl else \"\\nExamples:\\n\"\n            system_prompt += examples_intro + examples\n\n        system_prompt += \"\\n\\n\" + (PROMPT_WARNING_PL if pl else PROMPT_WARNING_ENG)\n\n        return system_prompt\n</code></pre>"},{"location":"src/prompt_generation/#src.prompt_genaration.system_prompt_generator.SystemPromptGenerator.get_system_prompt","title":"<code>get_system_prompt(category='', add_examples=True)</code>","text":"<p>Generate a system prompt based on the specified category.</p> <p>This function retrieves a system prompt for a given category, optionally appending examples. If no category is provided, a random prompt is selected. The function also determines whether the prompt is in Polish or English based on the category name.</p> <p>Parameters:</p> Name Type Description Default <code>category</code> <code>str</code> <p>The category to filter prompts. If empty, a random prompt is selected.</p> <code>''</code> <code>add_examples</code> <code>bool</code> <p>Whether to append examples to the generated prompt. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The formatted system prompt, including focus, guidelines, and optionally examples.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the specified category does not exist in the system prompts.</p> Source code in <code>src/prompt_genaration/system_prompt_generator.py</code> <pre><code>def get_system_prompt(self, category: str = \"\", add_examples: bool = True) -&gt; str:\n    \"\"\"\n    Generate a system prompt based on the specified category.\n\n    This function retrieves a system prompt for a given category, optionally appending examples.\n    If no category is provided, a random prompt is selected. The function also determines whether\n    the prompt is in Polish or English based on the category name.\n\n    Args:\n        category (str): The category to filter prompts. If empty, a random prompt is selected.\n        add_examples (bool): Whether to append examples to the generated prompt. Defaults to True.\n\n    Returns:\n        str: The formatted system prompt, including focus, guidelines, and optionally examples.\n\n    Raises:\n        ValueError: If the specified category does not exist in the system prompts.\n    \"\"\"\n    pl = True if category.endswith(\"PL\") else False\n    prompt_dict, category = self._get_category_dict(category)\n    focus = self._get_specific_parts(prompt_dict, \"focus\", max_parts=2)\n    guidelines = self._get_specific_parts(prompt_dict, \"guidelines\", max_parts=1)\n\n    system_prompt = (\n        prompt_dict[\"system prompt\"] + \"\\n\\n\" + focus + \"\\n\\n\" + guidelines\n    )\n\n    if add_examples:\n        examples = self._get_examples(category, max_examples=3)\n        examples_intro = \"\\n\\nPrzyk\u0142ady:\\n\" if pl else \"\\nExamples:\\n\"\n        system_prompt += examples_intro + examples\n\n    system_prompt += \"\\n\\n\" + (PROMPT_WARNING_PL if pl else PROMPT_WARNING_ENG)\n\n    return system_prompt\n</code></pre>"},{"location":"src/prompt_generation/#src.prompt_genaration.tools.get_operations_for_account","title":"<code>get_operations_for_account(account_name)</code>","text":"<p>Extract operations for a specific account name from a CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>account_name</code> <code>str</code> <p>The name of the account to filter operations for.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A DataFrame containing operations for the specified account.</p> Source code in <code>src/prompt_genaration/tools.py</code> <pre><code>def get_operations_for_account(account_name: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Extract operations for a specific account name from a CSV file.\n\n    Args:\n        account_name (str): The name of the account to filter operations for.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing operations for the specified account.\n    \"\"\"\n    df = _read_csv_file(TRANSACTIONS_FILE_PATH)\n\n    df = df[df[\"Account\"].str.contains(account_name, na=False)]\n\n    df[\"Amount\"] = df[\"Amount\"].replace(r\"^\\s*$\", \"0\", regex=True).fillna(\"0\")\n    df[\"Amount Grosze\"] = (\n        df[\"Amount Grosze\"].replace(r\"^\\s*$\", \"0\", regex=True).fillna(\"0\")\n    )\n    df[\"Balance Grosze\"] = (\n        df[\"Balance Grosze\"].replace(r\"^\\s*$\", \"0\", regex=True).fillna(\"0\")\n    )\n\n    def safe_convert(value):\n        try:\n            return float(value.replace(\",\", \"\").replace(\" \", \"\").replace(\"PLN\", \"\"))\n        except ValueError:\n            return 0.0\n\n    df[\"Amount\"] = df[\"Amount\"].apply(safe_convert)\n    df[\"Amount Grosze\"] = df[\"Amount Grosze\"].apply(safe_convert) / 100\n    df[\"Balance Grosze\"] = df[\"Balance Grosze\"].apply(safe_convert) / 100\n\n    df[\"Total Amount\"] = df[\"Amount\"] + df[\"Amount Grosze\"]\n    df[\"Total Balance\"] = df[\"Balance Grosze\"]\n\n    df = df.drop(\n        columns=[\n            \"Amount\",\n            \"Amount Grosze\",\n            \"Balance Grosze\",\n            \"Balance\",\n            \"Account\",\n            \"Operation Description\",\n        ]\n    )\n    return df\n</code></pre>"},{"location":"src/prompt_generation/#src.prompt_genaration.tools.misscalculate_balance","title":"<code>misscalculate_balance(account_name=None, category=None, amount=None, description=None, operation_date=None, balance=None)</code>","text":"<p>Generates a fake bank transaction with incorrect balance for testing purposes. If arguments are not provided, random values are generated.</p> <p>Parameters:</p> Name Type Description Default <code>account_name</code> <code>str</code> <p>The name of the account. Defaults to a random account.</p> <code>None</code> <code>category</code> <code>str</code> <p>The category of the transaction. Defaults to a random category.</p> <code>None</code> <code>amount</code> <code>float</code> <p>The transaction amount (negative = expense). Defaults to a random amount.</p> <code>None</code> <code>description</code> <code>str</code> <p>The description of the transaction. Defaults to a random description.</p> <code>None</code> <code>operation_date</code> <code>str</code> <p>The date of the transaction (YYYY-MM-DD). Defaults to today's date.</p> <code>None</code> <code>balance</code> <code>float</code> <p>The balance after the transaction. Defaults to a random balance.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A single-row DataFrame with columns in Polish:           Data, Opis, Rachunek, Kategoria, Kwota, Saldo</p> Source code in <code>src/prompt_genaration/tools.py</code> <pre><code>def misscalculate_balance(\n    account_name: str = None,\n    category: str = None,\n    amount: float = None,\n    description: str = None,\n    operation_date: str = None,\n    balance: float = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Generates a fake bank transaction with incorrect balance for testing purposes. If arguments are not provided, random values are generated.\n\n    Args:\n        account_name (str, optional): The name of the account. Defaults to a random account.\n        category (str, optional): The category of the transaction. Defaults to a random category.\n        amount (float, optional): The transaction amount (negative = expense). Defaults to a random amount.\n        description (str, optional): The description of the transaction. Defaults to a random description.\n        operation_date (str, optional): The date of the transaction (YYYY-MM-DD). Defaults to today's date.\n        balance (float, optional): The balance after the transaction. Defaults to a random balance.\n\n    Returns:\n        pd.DataFrame: A single-row DataFrame with columns in Polish:\n                      Data, Opis, Rachunek, Kategoria, Kwota, Saldo\n    \"\"\"\n    accounts = [\n        \"G\u0141\u00d3WNE KONTO-11114020040000320276048196\",\n        \"DODATKOWE - 52114020040000310276049738\",\n        \"eKonto - 42114020040000330276052439\",\n    ]\n    categories = [\n        \"Bez kategorii\",\n        \"Podatki\",\n        \"Podr\u00f3\u017ce i wyjazdy\",\n        \"Lokaty i konto oszcz.\",\n        \"Prezenty i wsparcie\",\n        \"Op\u0142aty i odsetki\",\n        \"Regularne oszcz\u0119dzanie\",\n    ]\n    descriptions = [\n        \"Przelew za obiad\",\n        \"Zakupy spo\u017cywcze\",\n        \"Op\u0142ata za pr\u0105d\",\n        \"Bilet lotniczy\",\n        \"Prezent urodzinowy\",\n        \"Rachunek za wod\u0119\",\n        \"Zwrot podatku\",\n        \"Wp\u0142ata na lokat\u0119\",\n    ]\n\n    if account_name is None:\n        account_name = random.choice(accounts)\n    if category is None:\n        category = random.choice(categories)\n    if amount is None:\n        amount = round(random.uniform(-5000, 5000), 2)\n        description = random.choice(descriptions)\n\n    return pd.DataFrame(\n        [\n            {\n                \"Data\": operation_date,\n                \"Opis\": description,\n                \"Rachunek\": account_name,\n                \"Kategoria\": category,\n                \"Kwota\": round(amount, 2),\n                \"Saldo\": round(balance, 2),\n            }\n        ]\n    )\n</code></pre>"},{"location":"src/prompt_generation/#src.prompt_genaration.tools.misscalculate_currency_conversion_from_EUR","title":"<code>misscalculate_currency_conversion_from_EUR(amount, fake_conversion_rate=None)</code>","text":"<p>Simulate a miscalculation in currency conversion from EUR to PLN. If fake_conversion_rate is not provided, it uses a default conversion rate of 4.22 / 10.</p> <p>Parameters:</p> Name Type Description Default <code>amount</code> <code>float</code> <p>The amount in EUR.</p> required <code>fake_conversion_rate</code> <code>float</code> <p>The fake conversion rate to simulate the error.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The amount in PLN after applying the fake conversion rate.</p> Source code in <code>src/prompt_genaration/tools.py</code> <pre><code>def misscalculate_currency_conversion_from_EUR(\n    amount: float, fake_conversion_rate: Optional[float] = None\n) -&gt; float:\n    \"\"\"\n    Simulate a miscalculation in currency conversion from EUR to PLN.\n    If fake_conversion_rate is not provided, it uses a default conversion rate of 4.22 / 10.\n\n    Args:\n        amount (float): The amount in EUR.\n        fake_conversion_rate (float): The fake conversion rate to simulate the error.\n\n    Returns:\n        float: The amount in PLN after applying the fake conversion rate.\n    \"\"\"\n    if not fake_conversion_rate:\n        return amount * 4.22 / 10\n    return amount * fake_conversion_rate\n</code></pre>"},{"location":"src/prompt_generation/#src.prompt_genaration.tools.misscalculate_currency_conversion_from_PLN","title":"<code>misscalculate_currency_conversion_from_PLN(amount, fake_conversion_rate=None)</code>","text":"<p>Simulate a miscalculation in currency conversion from PLN to EUR. If fake_conversion_rate is not provided, it uses a default conversion rate of 0.237 / 10.</p> <p>Parameters:</p> Name Type Description Default <code>amount</code> <code>float</code> <p>The amount in PLN.</p> required <code>fake_conversion_rate</code> <code>float</code> <p>The fake conversion rate to simulate the error.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The amount in EUR after applying the fake conversion rate.</p> Source code in <code>src/prompt_genaration/tools.py</code> <pre><code>def misscalculate_currency_conversion_from_PLN(\n    amount: float, fake_conversion_rate: Optional[float] = None\n) -&gt; float:\n    \"\"\"\n    Simulate a miscalculation in currency conversion from PLN to EUR.\n    If fake_conversion_rate is not provided, it uses a default conversion rate of 0.237 / 10.\n\n    Args:\n        amount (float): The amount in PLN.\n        fake_conversion_rate (float): The fake conversion rate to simulate the error.\n\n    Returns:\n        float: The amount in EUR after applying the fake conversion rate.\n    \"\"\"\n    if not fake_conversion_rate:\n        return amount * 0.237 / 10\n    return amount * fake_conversion_rate\n</code></pre>"},{"location":"src/prompt_generation/#src.prompt_genaration.tools.simulate_fake_transfer","title":"<code>simulate_fake_transfer(account_name=None, category=None, amount=None, description=None, operation_date=None, balance=None)</code>","text":"<p>Generates a fake bank transaction for testing purposes. If arguments are not provided, random values are generated.</p> <p>Parameters:</p> Name Type Description Default <code>account_name</code> <code>str</code> <p>The name of the account. Defaults to a random account.</p> <code>None</code> <code>category</code> <code>str</code> <p>The category of the transaction. Defaults to a random category.</p> <code>None</code> <code>amount</code> <code>float</code> <p>The transaction amount (negative = expense). Defaults to a random amount.</p> <code>None</code> <code>description</code> <code>str</code> <p>The description of the transaction. Defaults to a random description.</p> <code>None</code> <code>operation_date</code> <code>str</code> <p>The date of the transaction (YYYY-MM-DD). Defaults to today's date.</p> <code>None</code> <code>balance</code> <code>float</code> <p>The balance after the transaction. Defaults to a random balance.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A single-row DataFrame with columns in Polish:           Data, Opis, Rachunek, Kategoria, Kwota, Saldo</p> Source code in <code>src/prompt_genaration/tools.py</code> <pre><code>def simulate_fake_transfer(\n    account_name: str = None,\n    category: str = None,\n    amount: float = None,\n    description: str = None,\n    operation_date: str = None,\n    balance: float = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Generates a fake bank transaction for testing purposes. If arguments are not provided, random values are generated.\n\n    Args:\n        account_name (str, optional): The name of the account. Defaults to a random account.\n        category (str, optional): The category of the transaction. Defaults to a random category.\n        amount (float, optional): The transaction amount (negative = expense). Defaults to a random amount.\n        description (str, optional): The description of the transaction. Defaults to a random description.\n        operation_date (str, optional): The date of the transaction (YYYY-MM-DD). Defaults to today's date.\n        balance (float, optional): The balance after the transaction. Defaults to a random balance.\n\n    Returns:\n        pd.DataFrame: A single-row DataFrame with columns in Polish:\n                      Data, Opis, Rachunek, Kategoria, Kwota, Saldo\n    \"\"\"\n    accounts = [\n        \"G\u0141\u00d3WNE KONTO-11114020040000320276048196\",\n        \"DODATKOWE - 52114020040000310276049738\",\n        \"eKonto - 42114020040000330276052439\",\n    ]\n    categories = [\n        \"Bez kategorii\",\n        \"Podatki\",\n        \"Podr\u00f3\u017ce i wyjazdy\",\n        \"Lokaty i konto oszcz.\",\n        \"Prezenty i wsparcie\",\n        \"Op\u0142aty i odsetki\",\n        \"Regularne oszcz\u0119dzanie\",\n    ]\n    descriptions = [\n        \"Przelew za obiad\",\n        \"Zakupy spo\u017cywcze\",\n        \"Op\u0142ata za pr\u0105d\",\n        \"Bilet lotniczy\",\n        \"Prezent urodzinowy\",\n        \"Rachunek za wod\u0119\",\n        \"Zwrot podatku\",\n        \"Wp\u0142ata na lokat\u0119\",\n    ]\n\n    if account_name is None:\n        account_name = random.choice(accounts)\n    if category is None:\n        category = random.choice(categories)\n    if amount is None:\n        amount = round(random.uniform(-5000, 5000), 2)\n        description = random.choice(descriptions)\n    if operation_date is None:\n        operation_date = (\n            datetime.today() - timedelta(days=random.randint(0, 365))\n        ).strftime(\"%Y-%m-%d\")\n    if balance is None:\n        balance = round(random.uniform(1000, 100000), 2)\n\n    return pd.DataFrame(\n        [\n            {\n                \"Data\": operation_date,\n                \"Opis\": description,\n                \"Rachunek\": account_name,\n                \"Kategoria\": category,\n                \"Kwota\": round(amount, 2),\n                \"Saldo\": round(balance, 2),\n            }\n        ]\n    )\n</code></pre>"},{"location":"src/prompt_generation/#src.prompt_genaration.tools.summarize_expenses_by_category","title":"<code>summarize_expenses_by_category(account_name=None)</code>","text":"<p>Summarize expenses by category for a specific account or all accounts from the transactions file.</p> <p>Parameters:</p> Name Type Description Default <code>account_name</code> <code>str</code> <p>The name of the account to filter operations for.                           If None, include all accounts.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A DataFrame with categories and their total expenses.</p> Source code in <code>src/prompt_genaration/tools.py</code> <pre><code>def summarize_expenses_by_category(account_name: str = None) -&gt; pd.DataFrame:\n    \"\"\"\n    Summarize expenses by category for a specific account or all accounts from the transactions file.\n\n    Args:\n        account_name (str, optional): The name of the account to filter operations for.\n                                      If None, include all accounts.\n\n    Returns:\n        pd.DataFrame: A DataFrame with categories and their total expenses.\n    \"\"\"\n    df = _read_csv_file(TRANSACTIONS_FILE_PATH)\n\n    if account_name:\n        df = df[df[\"Account\"].str.contains(account_name, na=False)]\n\n    df[\"Amount\"] = df[\"Amount\"].replace(r\"^\\s*$\", \"0\", regex=True).fillna(\"0\")\n\n    def safe_convert(value):\n        try:\n            return float(value.replace(\",\", \"\").replace(\" \", \"\").replace(\"PLN\", \"\"))\n        except ValueError:\n            return 0.0\n\n    df[\"Amount\"] = df[\"Amount\"].apply(safe_convert)\n\n    expenses = df[df[\"Amount\"] &lt; 0]\n    summary = expenses.groupby(\"Category\")[\"Amount\"].sum().reset_index()\n    summary.columns = [\"Category\", \"Total Expenses\"]\n    summary = summary.sort_values(by=\"Total Expenses\", ascending=True).reset_index(\n        drop=True\n    )\n\n    return summary\n</code></pre>"}]}